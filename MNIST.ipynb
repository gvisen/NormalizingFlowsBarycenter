{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8241d1-9c16-4f51-b83b-8b41f20bb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import normflows as nf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# own imports\n",
    "from src.bases import CategoricalBase\n",
    "from src.datasets import MNISTSampler, SXDataset\n",
    "from src.utils import check_mem\n",
    "from src.flows import SXGlowBlock, Squeeze, Sigmoid\n",
    "from src.models import SXNormalizingFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3ccdd-ee45-490e-a9fb-b52710eafa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "check_mem(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b4ac6-d780-40ff-99b6-0af98009261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f61e1-1a94-4a52-955f-2a9dc88f7e60",
   "metadata": {},
   "source": [
    "# MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0488b-ef2d-4f7b-9169-93763094c00d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "dataset_path = 'data'\n",
    "\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((img_size, img_size)),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Lambda(lambda x: torch.clip(x,0,1))\n",
    "])\n",
    "\n",
    "dataset = tv.datasets.MNIST(root=dataset_path,\n",
    "                                     download=True, \n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13120b3-d8bc-43a8-98be-45bca971a854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Indices of digit distributions, must be a subset of {0, ..., 9}\n",
    "# Choose one of the following:\n",
    "# 1. For the all digits experiment.\n",
    "digit_idxs = list(range(10))\n",
    "# 2. For the {0, 1} experiment:\n",
    "# digit_idxs = [0, 1]\n",
    "\n",
    "# input distributions weights\n",
    "alphas = torch.ones(len(digit_idxs))/len(digit_idxs) \n",
    "\n",
    "x_samplers = []\n",
    "for digit_idx in digit_idxs:\n",
    "    x_samplers.append(MNISTSampler(dataset, digit_idx, device=device))\n",
    "\n",
    "s_base = CategoricalBase(alphas, one_hot_encoded=True)\n",
    "dataset = SXDataset(x_samplers, s_base, num_samples=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730af8fd-20d8-4956-bda4-7139f84576e8",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5451a-37ab-41c8-878f-297fafb5182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of scales (a.k.a. levels)\n",
    "L = 4\n",
    "\n",
    "# Number of flows per scale\n",
    "K = 16\n",
    "\n",
    "input_shape = (1, 32, 32)\n",
    "n_dims = np.prod(input_shape)\n",
    "channels = 1\n",
    "hidden_channels = 256\n",
    "split_mode = 'channel'\n",
    "scale = True\n",
    "\n",
    "z_bases = []\n",
    "merges = []\n",
    "flows = []\n",
    "for i in range(L):\n",
    "    print(f'Scale {i}')\n",
    "    \n",
    "    flows_ = []\n",
    "    for j in range(K):\n",
    "        flows_ += [SXGlowBlock(channels * 2 ** (L + 1 - i), \n",
    "                               hidden_channels, \n",
    "                               context_dim=s_base.dim,\n",
    "                               split_mode=split_mode, \n",
    "                               scale=scale)]\n",
    "    flows_ += [Squeeze()]\n",
    "\n",
    "    # Add (stretched) sigmoid transformation as last flow\n",
    "    if i == L-1:\n",
    "        flows_ += [Sigmoid(eps=1e-5)]\n",
    "    \n",
    "    flows += [flows_]\n",
    "    \n",
    "    if i > 0:\n",
    "        merges += [nf.flows.Merge()]\n",
    "        latent_shape = (input_shape[0] * 2 ** (L - i), input_shape[1] // 2 ** (L - i), \n",
    "                        input_shape[2] // 2 ** (L - i))\n",
    "    else:\n",
    "        latent_shape = (input_shape[0] * 2 ** (L + 1), input_shape[1] // 2 ** L, \n",
    "                        input_shape[2] // 2 ** L)\n",
    "\n",
    "    z_bases += [nf.distributions.DiagGaussian(latent_shape, trainable=False)]\n",
    "\n",
    "\n",
    "# Construct flow model with the multiscale architecture\n",
    "model = SXNormalizingFlow(z_bases, s_base, flows, merges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d63f50-b63e-47bf-a5ee-a24993bc6a89",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c95284-5544-40e4-8419-d182ad742e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50000\n",
    "\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "\n",
    "# print metrics every `print_epochs` epochs\n",
    "print_epochs = 1000 \n",
    "\n",
    "save_epochs = 5000\n",
    "milestones = []\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "\n",
    "model.to(device)\n",
    "alphas = alphas.to(device)\n",
    "\n",
    "kld_losses = []\n",
    "l2_losses = [] \n",
    "losses = []\n",
    "\n",
    "# annealing schedule\n",
    "temp = 10**torch.linspace(1, -2, epochs)\n",
    "\n",
    "train_loop = tqdm(range(epochs))\n",
    "for epoch in train_loop:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dataset = SXDataset(x_samplers, s_base, num_samples=batch_size)\n",
    "        s, x = dataset[:]\n",
    "        \n",
    "    # Compute KLD loss\n",
    "    kld_loss = model.forward_kld(x, s=s)\n",
    "        \n",
    "    # Compute L2 loss\n",
    "    z, _ = model.inverse_and_log_det(x, s)\n",
    "    l2_loss = torch.mean(torch.sum((x - model.bar(z))**2, dim=1))\n",
    "    \n",
    "    if torch.isnan(l2_loss):\n",
    "        loss = kld_loss\n",
    "    else:\n",
    "        loss = temp[epoch]*l2_loss + kld_loss\n",
    "    \n",
    "    \n",
    "    if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1., norm_type=2.0, error_if_nonfinite=False, foreach=True)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    l2_losses.append(l2_loss.item())\n",
    "    kld_losses.append(kld_loss.item())\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    train_loop.set_postfix(l2_loss=l2_loss.item(), \n",
    "                           kld_loss=kld_loss.item(), \n",
    "                           loss=loss.item(),\n",
    "                           lr=optimizer.param_groups[0][\"lr\"], \n",
    "                           temp=temp[epoch].item())\n",
    "\n",
    "    # Check learning at training time\n",
    "    if (epoch + 1) % print_epochs == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'KLD loss: {kld_loss.item()}')\n",
    "        print(f'lr: {optimizer.param_groups[0][\"lr\"]}')\n",
    "        \n",
    "        # Plot learned marginals\n",
    "        temperature = 1.\n",
    "        num_samples = 32\n",
    "        for i in range(len(digit_idxs)):\n",
    "            with torch.no_grad():\n",
    "                s = model.s_base.encode(i*torch.ones((num_samples, 1), dtype=torch.int64, device=device))\n",
    "                images, _ = model.sample(num_samples=num_samples, s=s, temperature=temperature)\n",
    "                imshow(tv.utils.make_grid(images.detach().cpu()))\n",
    "\n",
    "        # Plot sample from learned barycenter\n",
    "        print('Sample from barycenter.')\n",
    "        with torch.no_grad():\n",
    "            images = model.bar_sample(num_samples=num_samples, temperature=temperature)\n",
    "            imshow(tv.utils.make_grid(images.detach().cpu()))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f5047-9582-4da6-8fa3-80ff78b9def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "plt.plot(-np.log(np.abs(kld_losses)), 'b.-', label='KLD loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.log(l2_losses), 'y.-', label='L2 loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(losses, 'r.-', label='Total loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
