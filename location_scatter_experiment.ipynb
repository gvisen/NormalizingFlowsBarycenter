{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb03ef-b8ae-407c-98d2-8c24db81d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "import normflows as nf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.stats import special_ortho_group\n",
    "\n",
    "# imports from own modules\n",
    "from src.flows import SXAffineCouplingBlock, Permute\n",
    "from src.bases import SXBase, CategoricalBase, GaussianBase\n",
    "from src.models import SXNormalizingFlow\n",
    "from src.datasets import SXDataset\n",
    "from src.utils import check_mem, ConditionalMLP\n",
    "from src.samplers import Gaussian, Uniform, LocationScatterSampler, LocationScatterBenchmark\n",
    "from src.metrics import get_L2_UVP, get_BW2_UVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe11a9b-fc4a-4914-bf2e-06315f1c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cuda if available\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "check_mem(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3117be-cb43-4886-8a5e-6c317c31e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "# type of base distribution: either 'gaussian', or 'uniform'\n",
    "dataset_type = 'gaussian' \n",
    "\n",
    "# number of input distributions\n",
    "n = 4 \n",
    "\n",
    "# input dimension\n",
    "d = 2\n",
    "\n",
    "# distribution weights\n",
    "alphas = torch.tensor([0.1, 0.2, 0.3, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516d425-a2f9-462d-a50b-003b12dffd1f",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ac554-a3da-4cbb-9af8-cf54aa4922d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate datasets\n",
    "\n",
    "if dataset_type == 'gaussian':\n",
    "    base_sampler = Gaussian(d, device=device)\n",
    "elif dataset_type == 'uniform':\n",
    "    base_sampler = Uniform(d, device=device)\n",
    "else:\n",
    "    raise ValueError(f'Unknown dataset_type: {dataset_type}')\n",
    "\n",
    "samplers = []\n",
    "\n",
    "for i_sampler in range(n):\n",
    "    rotation = torch.tensor(special_ortho_group.rvs(d), dtype=torch.float)\n",
    "    b = pow(4, (1/(d-1)))\n",
    "    L = torch.diag(torch.tensor([0.5*(b**i) for i in range(d)]))\n",
    "    weight = rotation.T @ L @ rotation\n",
    "    bias = torch.zeros(d)\n",
    "    sampler = LocationScatterSampler(base_sampler, weight, bias, device=device)\n",
    "    samplers.append(sampler)    \n",
    "\n",
    "benchmark = LocationScatterBenchmark(base_sampler, samplers, alphas, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a477bf-5ce2-4234-8a1e-1372aabbf4aa",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d9c08-eba2-42c0-b93f-2b3ae0dbfe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model implementation\n",
    "\n",
    "# number of scales (a.k.a. levels)\n",
    "L = int(np.log2(d)) \n",
    "\n",
    "# flows per scale\n",
    "if L == 1:\n",
    "    K = 32 \n",
    "elif L >= 2 and L <= 4:\n",
    "    K = 16\n",
    "else:\n",
    "    K = 8\n",
    "\n",
    "split_mode = 'channel'\n",
    "scale = True\n",
    "\n",
    "# Latent space dimensions\n",
    "z_bases = []\n",
    "latent_dims = [2] + [2**i for i in range(1, L)] # latent dimensions at each scale\n",
    "assert sum(latent_dims) == d\n",
    "\n",
    "merges = []\n",
    "flows = []\n",
    "for i in range(L):\n",
    "    flows_ = []\n",
    "    for j in range(K):\n",
    "        # Get conditional MLP input/output dimensions at each level\n",
    "        z1, z2 = torch.rand((10, sum(latent_dims[:i+1]))).chunk(2, dim=1)\n",
    "        dim1 = z1.shape[1]\n",
    "        dim2 = 2*z2.shape[1] # mean and scale parameter for each channel in z2\n",
    "\n",
    "        # Add neural network conditioner\n",
    "        param_map = ConditionalMLP([dim1, 64, 64, dim2], context_dim=benchmark.num, init_zeros=True)\n",
    "        # Add flow layer\n",
    "        flows_.append(SXAffineCouplingBlock(param_map, scale=True, scale_map=\"exp\", split_mode=\"channel\"))\n",
    "        # Randomly permute dimensions\n",
    "        flows_.append(Permute(sum(latent_dims[:i+1]), mode='shuffle'))\n",
    "\n",
    "    flows.append(flows_)\n",
    "\n",
    "    z_bases.append(nf.distributions.DiagGaussian(latent_dims[i], trainable=False))\n",
    "    if i > 0:\n",
    "        merges.append(nf.flows.Merge())\n",
    "\n",
    "# Instantiate model\n",
    "s_base = CategoricalBase(alphas, one_hot_encoded=True)\n",
    "model = SXNormalizingFlow(z_bases, s_base, flows, merges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4e0db-6a05-452e-a0dd-3201d97ef51f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f8209-80bc-414b-928f-987824336fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 10000\n",
    "\n",
    "# Learning rate\n",
    "if dataset_type == 'gaussian':\n",
    "    lr = 1e-3\n",
    "else:\n",
    "    lr = 1e-4\n",
    "\n",
    "# print metrics every `print_epochs` epochs\n",
    "print_epochs = 10 \n",
    "\n",
    "# decreasing weights schedule\n",
    "temp = 10**torch.linspace(0, -2, epochs)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.8, \n",
    "                                                       patience=1000, \n",
    "                                                       threshold=0.0001, \n",
    "                                                       threshold_mode='abs', \n",
    "                                                       min_lr=1e-8, \n",
    "                                                       eps=1e-08, \n",
    "                                                       verbose='deprecated')\n",
    "\n",
    "model.to(device)\n",
    "alphas = alphas.to(device)\n",
    "\n",
    "kld_losses = []\n",
    "l2_losses = [] \n",
    "losses = []\n",
    "scores = []\n",
    "\n",
    "train_loop = tqdm(range(epochs))\n",
    "\n",
    "for epoch in train_loop:\n",
    "    \n",
    "    # Compute KLD loss\n",
    "    s, x = SXDataset(benchmark.samplers, model.s_base, num_samples=batch_size)[:]\n",
    "    kld_loss = model.forward_kld(x, s=s)\n",
    "    \n",
    "    # Compute L2 loss\n",
    "    z, _ = model.inverse_and_log_det(x, s)\n",
    "    l2_loss = torch.mean(torch.sum((x - model.bar(z))**2, dim=1))\n",
    "        \n",
    "    loss = temp[epoch]*l2_loss + kld_loss\n",
    "    \n",
    "    if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2., norm_type=2.0, error_if_nonfinite=False, foreach=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    l2_losses.append(l2_loss.item())\n",
    "    kld_losses.append(kld_loss.item())\n",
    "\n",
    "    if epoch % print_epochs == 0:\n",
    "        model.eval()\n",
    "        score = get_L2_UVP(benchmark, model, alphas, batch_size=1000, device=device)\n",
    "        model.train()\n",
    "        scores.append(score)\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    train_loop.set_postfix(l2_loss=l2_loss.item(), \n",
    "                           kld_loss=kld_loss.item(), \n",
    "                           lr=optimizer.param_groups[0][\"lr\"], \n",
    "                           temp=temp[epoch].item(),\n",
    "                           score=score)\n",
    "\n",
    "    scheduler.step(kld_loss)\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c99b9-46c0-409b-aad2-ac716c33d2b5",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b40cd-38ba-4898-9208-e1d544879dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot training losses\n",
    "\n",
    "plt.plot(kld_losses, 'b.-', label='KL div losses')\n",
    "plt.plot(l2_losses, 'y.-', label='L2 losses')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(losses, 'r.-', label='Total losses')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.log(scores), 'r.-')\n",
    "plt.title('L2_UVP score (log-%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acc19f-6102-46d1-a19e-9b630e61171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "\n",
    "# number of trials for computing standard deviation of metrics\n",
    "n_estimators = 10\n",
    "\n",
    "L2_UVPs = {'mean': [], 'std': []}\n",
    "BW2_UVPs = {'mean': [], 'std': []}\n",
    "\n",
    "# L2_UVP\n",
    "scores = torch.zeros(n_estimators)\n",
    "for i in range(scores.numel()):\n",
    "    scores[i] = get_L2_UVP(benchmark, model, alphas, batch_size=10000, device=device)\n",
    "L2_UVPs['mean'] = torch.mean(scores).item()\n",
    "L2_UVPs['std'] = torch.std(scores).item()\n",
    "\n",
    "# BW2_UVP\n",
    "scores = torch.zeros(n_estimators)\n",
    "for i in range(scores.numel()):\n",
    "    scores[i] = get_BW2_UVP(benchmark, model)\n",
    "BW2_UVPs['mean'] = torch.mean(scores).item()\n",
    "BW2_UVPs['std'] = torch.std(scores).item()\n",
    "\n",
    "# Print metrics\n",
    "print(f'L2_UVP (mean +- std): {L2_UVPs['mean']} +- {L2_UVPs['std']}\\n')\n",
    "print(f'BW2_UVP (mean +- std): {BW2_UVPs['mean']} +- {BW2_UVPs['std']}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596b10c-8fae-4e62-a65f-edd6d56ea29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
